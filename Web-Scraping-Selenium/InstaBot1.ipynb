{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()                                              #to create a web session\n",
    "driver.get(\"https://www.instagram.com/\")                                 #getting the instagram site\n",
    "wait = WebDriverWait(driver, 10)                                         #adding explicit wait for the page to load, passing the upper bound as 10 sec                           \n",
    "\n",
    "name = wait.until(EC.presence_of_element_located((By.NAME,'username')))    #locating the username textbox\n",
    "password= wait.until(EC.presence_of_element_located((By.NAME,'password'))) #locating the password textbox\n",
    "name.send_keys(\"SAMPLE USERNAME\")\n",
    "password.send_keys(\"SAMPLE PASSWORD\")\n",
    "submit_btn = driver.find_element_by_tag_name(\"button\")                     #locating the login button\n",
    "submit_btn.submit()\n",
    "time.sleep(2)                                                              # adding some waiting time for instagram to login\n",
    "try:\n",
    "    wait.until(EC.presence_of_element_located((By.XPATH,'//div/button[contains(@class,\"HoLwm\")]'))).click()\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Type “food” in search bar and print all the names of the Instagram Handles that are displayed in the list after typing “food”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foodgod\n",
      "foodnetwork\n",
      "buzzfeedfood\n",
      "foodbytania\n",
      "foodinsider\n",
      "fooddreamer\n",
      "food\n",
      "foodandwine\n",
      "foodmybff\n",
      "food52\n",
      "foodnewyork\n",
      "foodnetworkkitchen\n",
      "foodie_incarnate\n",
      "stickaforkinme\n",
      "foodgawker\n",
      "foodbeast\n",
      "foodfitnessflora\n",
      "foodgays\n",
      "foodkeen\n",
      "foodstupid\n",
      "annashealthyveganfood\n",
      "lizza\n",
      "foodprior\n",
      "healthyfoodadvice\n",
      "foodytops\n",
      "chocolateparadise\n",
      "food_gordo\n",
      "foodstyleguide\n",
      "foodsofjane\n",
      "foodyfetish\n",
      "loveanyfood\n",
      "delicioushealthyvideos\n",
      "diywhirl\n",
      "hairfoodarabia\n",
      "foodteller\n",
      "littlefoodco\n",
      "majorfoodgroup\n",
      "misscravingbuster\n",
      "dreamfood\n",
      "foodintheair\n",
      "food_lovers_mad\n",
      "noelsfoodjournal\n",
      "boyswhobrunchny\n",
      "tipsclever\n",
      "healthy.foodyss\n",
      "foodiecrush\n",
      "247tricks\n",
      "sweety.foody\n",
      "dogs_infood\n",
      "cchannel_food\n",
      "netflixfood\n",
      "foodiebiteguide\n",
      "ashpazidorehami\n"
     ]
    }
   ],
   "source": [
    "s_box = driver.find_element_by_xpath(\"//input[contains(@class,'XTCLo')]\")   #locating the search box\n",
    "#s_box.get_attribute(\"outerHTML\")\n",
    "s_box.send_keys(\"food\")\n",
    "time.sleep(2)\n",
    "handles = driver.find_elements_by_xpath(\"//div[@class='fuqBx']/*\")          #fetching the items that show on searching food\n",
    "li = []   \n",
    "for item in handles:\n",
    "    if 'explore' in item.get_attribute('href'):                             #removing the hashtags from the list\n",
    "        continue\n",
    "    else:       \n",
    "        s = item.get_attribute('href').split('/')                           #from the href remove the hashtags by splitting the link     \n",
    "        print(s[3])                                     \n",
    "        li.append(s[3])      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3)Searching and Opening a profile\n",
    "Open profile of “So Delhi”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_search = driver.find_element_by_xpath(\"//div[contains(@class,'coreSpriteSearchClear')]\")     #search the cross button to clear the search result\n",
    "clear_search.click()\n",
    "s_box.send_keys(\"So Delhi\")\n",
    "prof_= wait.until(EC.presence_of_element_located((By.XPATH,\"//a[@href = '/sodelhi/']\")))\n",
    "prof_.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow/Unfollow given handle -\n",
    "Open the Instagram Handle of “So Delhi”\n",
    "Start following it. Print a message already following After following, unfollow the instagram handle. Print a message if already unfollowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Account Followed\n",
      "Already Following So Delhi. \n",
      "Account Unfollowed\n",
      "Already Unfollowed\n"
     ]
    }
   ],
   "source": [
    "#Handle already opened\n",
    "#Now, For following the handle\n",
    "follow_btn = driver.find_element_by_xpath(\"//button[contains(text(),'Follow')]\")  #locating the follow button\n",
    "follow_btn.click()\n",
    "print(\"Account Followed\")\n",
    "time.sleep(3)\n",
    "a = driver.find_element_by_xpath(\"//button[contains(@class,'_5f5mN')]/div/span\")  #checking the button status \n",
    "if a.get_attribute(\"aria-label\") == 'Following':\n",
    "    print(\"Already Following So Delhi. \")\n",
    "time.sleep(2)\n",
    "    \n",
    "#Now, to unfollow the handle\n",
    "a.click()\n",
    "time.sleep(2)\n",
    "unfollow_btn = driver.find_element_by_xpath('//div[contains(@class,\"mt3GC\")]/button')\n",
    "unfollow_btn.click()\n",
    "print(\"Account Unfollowed\")\n",
    "\n",
    "if follow_btn.text == 'Following':\n",
    "    print(\"Already Following So Delhi. \")\n",
    "else:\n",
    "    print(\"Already Unfollowed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Like/Unlike posts\n",
    "Liking the top 30 posts of the ‘dilsefoodie'. Print message if already liked. Unliking the top 30 posts of the ‘dilsefoodie’. Print message if already unliked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_box = driver.find_element_by_xpath(\"//input[@placeholder = 'Search']\")\n",
    "s_box.send_keys(\"dilsefoodie\")\n",
    "x = wait.until(EC.presence_of_element_located((By.CLASS_NAME,'yCE8d ')))\n",
    "x.click()\n",
    "time.sleep(3)\n",
    "current_height = driver.execute_script('return document.body.scrollHeight;')   #using infinite scroll to find the top 30 posts\n",
    "while(len(driver.find_elements_by_xpath(\"//div[@class ='Nnq7C weEfm']\"))<10):  #scrolling till 10 rows as each contains 3 post\n",
    "    driver.execute_script('window.scrollBy(0,arguments[0]);', current_height)\n",
    "    new_height = driver.execute_script('return document.body.scrollHeight;')\n",
    "    current_height = new_height\n",
    "\n",
    "r = driver.find_elements_by_xpath(\"//div[@class ='Nnq7C weEfm']\")\n",
    "\n",
    "hrefs = [] \n",
    "for row in r:                                              #creating list of the href of each post\n",
    "    posts = row.find_elements_by_xpath(\"./*\")\n",
    "    for post in posts:\n",
    "        link = post.find_element_by_tag_name('a')\n",
    "        hrefs.append(link.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liked post  1\n",
      "Liked post  2\n",
      "Liked post  3\n",
      "Liked post  4\n",
      "Liked post  5\n",
      "Liked post  6\n",
      "Liked post  7\n",
      "Liked post  8\n",
      "Liked post  9\n",
      "Liked post  10\n",
      "Liked post  11\n",
      "Liked post  12\n",
      "Liked post  13\n",
      "Liked post  14\n",
      "Liked post  15\n",
      "Liked post  16\n",
      "Liked post  17\n",
      "Liked post  18\n",
      "Liked post  19\n",
      "Liked post  20\n",
      "Liked post  21\n",
      "Liked post  22\n",
      "Liked post  23\n",
      "Liked post  24\n",
      "Liked post  25\n",
      "Liked post  26\n",
      "Liked post  27\n",
      "Liked post  28\n",
      "Liked post  29\n",
      "Liked post  30\n"
     ]
    }
   ],
   "source": [
    "# Liking top 30 posts\n",
    "count = 0\n",
    "for pic in hrefs:\n",
    "    driver.get(pic)\n",
    "\n",
    "    status = wait.until(EC.presence_of_element_located((By.XPATH,\"//*[name()='svg']\")))\n",
    "    label = status.get_attribute('aria-label')            #checking the status of post\n",
    "    if label=='Unlike':\n",
    "        print(\"Already Liked\")\n",
    "    else:\n",
    "        like_btn = status.find_element_by_xpath(\"./..\")\n",
    "        like_btn.click()\n",
    "        count+=1\n",
    "        print(\"Liked post \",count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unliked post  1\n",
      "Unliked post  2\n",
      "Unliked post  3\n",
      "Unliked post  4\n",
      "Unliked post  5\n",
      "Unliked post  6\n",
      "Unliked post  7\n",
      "Unliked post  8\n",
      "Unliked post  9\n",
      "Unliked post  10\n",
      "Unliked post  11\n",
      "Unliked post  12\n",
      "Unliked post  13\n",
      "Unliked post  14\n",
      "Unliked post  15\n",
      "Unliked post  16\n",
      "Unliked post  17\n",
      "Unliked post  18\n",
      "Unliked post  19\n",
      "Unliked post  20\n",
      "Unliked post  21\n",
      "Unliked post  22\n",
      "Unliked post  23\n",
      "Unliked post  24\n",
      "Unliked post  25\n",
      "Unliked post  26\n",
      "Unliked post  27\n",
      "Unliked post  28\n",
      "Unliked post  29\n",
      "Unliked post  30\n"
     ]
    }
   ],
   "source": [
    "# Unlike liked images\n",
    "count=0\n",
    "for pic in hrefs:\n",
    "    driver.get(pic)\n",
    "    status = wait.until(EC.presence_of_element_located((By.XPATH,\"//*[name()='svg']\")))\n",
    "    label = status.get_attribute('aria-label')                 #checkinh the status and then unliking the post\n",
    "    if label=='Unlike':\n",
    "        like_btn = status.find_element_by_xpath(\"./..\")\n",
    "        like_btn.click()\n",
    "        count+=1\n",
    "        print(\"Unliked post \",count) \n",
    "    else:\n",
    "        print(\"Already Unliked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6)Extract list of 500 followers\n",
    "Extract the usernames of the first 500 followers of ‘foodtalkindia’ and ‘sodelhi’. Now print all the followers of “foodtalkindia” that you are following but those who don’t follow you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = ['foodtalkindia','sodelhi']    #creating a list of profiles\n",
    "followers = []\n",
    "for profile in profiles:\n",
    "    s_box = wait.until(EC.presence_of_element_located((By.XPATH,\"//input[@placeholder = 'Search']\"))) \n",
    "    s_box.send_keys(profile)\n",
    "    xp = \"//a[@href = '/\" + profile + \"/']\"              #creating a general way for both profiles\n",
    "    follxp = \"//a[@href = '/\" + profile + \"/followers/']\"\n",
    "    element = wait.until(EC.presence_of_element_located((By.XPATH,xp)))\n",
    "    element.click()\n",
    "    element = wait.until(EC.presence_of_element_located((By.XPATH,follxp)))\n",
    "    element.click()\n",
    "\n",
    "    dialog = wait.until(EC.presence_of_element_located((By.XPATH,\"//div[@role = 'dialog']\")))\n",
    "    div = wait.until(EC.presence_of_element_located((By.CLASS_NAME,'PZuss')))  #waiting till the list of followers appears\n",
    "\n",
    "    fols = wait.until(EC.presence_of_element_located((By.CLASS_NAME,'isgrP')))\n",
    "    counter_ = len(div.find_elements_by_tag_name(\"li\"))       #finding the elements with li tag\n",
    "    \n",
    "    while counter_ < 500:          # scrolling till 500 followers\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", fols)\n",
    "        new_count = len(div.find_elements_by_tag_name(\"li\"))\n",
    "        time.sleep(1)\n",
    "        counter_ = new_count\n",
    "    \n",
    "    div = driver.find_element_by_class_name('PZuss')\n",
    "    followers_list = div.find_elements_by_xpath(\"./li\")\n",
    "    followers.append([])\n",
    "    \n",
    "    for pf in followers_list:                   #extracting the names from the hrefs\n",
    "        name = pf.find_element_by_xpath('div/div[1]/div[2]/div[1]/a').text\n",
    "        followers[profiles.index(profile)].append(name)\n",
    "    \n",
    "    close = driver.find_element_by_xpath(\"//*[@aria-label='Close']\")\n",
    "    close.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "First 500 followers of  foodtalkindia : \n",
      "-------------------------------------\n",
      "mohitmohit26\n",
      "foodcrafts20\n",
      "dank_puluthi\n",
      "069karthik\n",
      "jyo.ti2015\n",
      "sandhya_home_cooking\n",
      "thaatgirll\n",
      "traveller.0493\n",
      "travel_h_o_l_i_c\n",
      "athena.sule\n",
      "aarti.kalra.921\n",
      "oye_foodie_kidda\n",
      "kriedal\n",
      "rohitaggarwal08\n",
      "buddingchef_chriz\n",
      "poovanes_22\n",
      "rajvansh_07\n",
      "theteaculture\n",
      "surbhi24422\n",
      "sunandasinghal\n",
      "wimpyarora\n",
      "beatnik.nowhere\n",
      "_foodie_chics_\n",
      "ac_jaynidixit_kunvar\n",
      "_blossomgirl_11\n",
      "what.wecrave\n",
      "finosophy_\n",
      "hungrygoan\n",
      "foodqueen32\n",
      "amieshah02\n",
      "chandan.khairwar\n",
      "1927___fatima\n",
      "king_of_brand_nick_\n",
      "frenchieflys\n",
      "_x__v.key__x_\n",
      "offrenew\n",
      "mr.psyco1_4_3\n",
      "_vegforlife\n",
      "eatwith_vick\n",
      "kanikamehrotra\n",
      "_____public_ke_zuban_____\n",
      "acouple0f_f00dies\n",
      "food_pari\n",
      "shebayeru\n",
      "chandraprakash7679\n",
      "prateek_______99\n",
      "trikish_yumm\n",
      "rbgala82\n",
      "foodiekomal\n",
      "allthatbakes\n",
      "karuna_mishra\n",
      "juhi_raithatha\n",
      "talented_mrt\n",
      "achuta.lakshmi\n",
      "chefprav\n",
      "encase_design_studio\n",
      "arunmohan_06\n",
      "itz_sumit_xx\n",
      "foodienandiee\n",
      "tuestiloalamoda1\n",
      "rashmi_kishore\n",
      "foodandtravelonloop\n",
      "carbonarrapizza_\n",
      "the_indian_taste\n",
      "adi_chauhan978\n",
      "positive_men_in_world\n",
      "asrefcon.co.in\n",
      "lakhvinder_saini_\n",
      "ruhul0250\n",
      "fooodiebuddie\n",
      "rinshadu\n",
      "hungry.merlin\n",
      "aveeshakaur\n",
      "lalukababeeofficial\n",
      "imam_r.s_\n",
      "sachinpuranepatil\n",
      "desivesikhana\n",
      "sativas.kitchen\n",
      "thequarantinebaker_\n",
      "chefazam__shk\n",
      "zaryskitchen\n",
      "tonnysalinasok\n",
      "shanillagade\n",
      "fernz_93\n",
      "urbantapricafe\n",
      "maa_papa_aaur_mai\n",
      "nainaj8\n",
      "shikha.nandwani\n",
      "heena.jetley75\n",
      "atiolia\n",
      "mariate.d\n",
      "ashdixit\n",
      "coffee_and_hills\n",
      "food_malarkey\n",
      "kitchen_ninja2418\n",
      "hotel_millath_\n",
      "simplyfoods9\n",
      "kouraniv\n",
      "rajendrarajendra406\n",
      "food_speak\n",
      "roohisamad\n",
      "samrasuhail\n",
      "deepakbagiyal27\n",
      "wefoodysouls\n",
      "globe921\n",
      "smiti27\n",
      "belly_n_beauty\n",
      "mr.rebel_302\n",
      "anujajayakrishnan\n",
      "rg_party_organizers\n",
      "nashtemeinkyahai\n",
      "sm_pvt26\n",
      "the_indi_world\n",
      "shezaferoz_\n",
      "amazonhub60\n",
      "royal_tastedelhi\n",
      "ansofficialss\n",
      "swadaaanusar\n",
      "mukta_walecha\n",
      "spandy0209\n",
      "kiwamibox_jp\n",
      "santript_bhojan\n",
      "foodiebyheart________\n",
      "sugraniskitchen\n",
      "bcihmct.media\n",
      "naaamiisshhaaa\n",
      "_twinklearora_19\n",
      "muskaan_dank14\n",
      "foodieparidhi\n",
      "wonderfrutzofficial\n",
      "menaalskitchen\n",
      "deshmukhkirti38\n",
      "justkaran\n",
      "tigerarya2222\n",
      "silvercoin_atta\n",
      "refectionsthejuicebar\n",
      "_imtushar__\n",
      "muuuhhhhaaaaa\n",
      "theshadrasa\n",
      "bhukkad_nah\n",
      "unboxed_designs\n",
      "deepkas\n",
      "fresh_on_the_plate_\n",
      "aanchaltambi\n",
      "the_trunk_safari\n",
      "hungry_delhi_boy\n",
      "i_abhii10\n",
      "vineeth_vista\n",
      "ganeshg1999\n",
      "maferdice\n",
      "rupashetty80\n",
      "ashiji_ka_khana\n",
      "711vaibhav\n",
      "kartik.40\n",
      "saini.shubz09\n",
      "chubby_cheeks_143\n",
      "jain_tinkesh_parikh\n",
      "scotcholic\n",
      "herbileofficial\n",
      "loveyouahmedabad\n",
      "kumar.manjula\n",
      "diyakoshi\n",
      "mandeep_s._basra\n",
      "aishwarya.rao.d\n",
      "fotograaph_\n",
      "deeps11792\n",
      "priyankabastin\n",
      "gymlovers2178\n",
      "yb_yashwantban\n",
      "vk_sipandbites\n",
      "meeral.shah06\n",
      "foodie_kmnafee\n",
      "mala.khadija\n",
      "foodtrav9\n",
      "al_hennna\n",
      "bridalcloset20\n",
      "kesavaraj1996\n",
      "vibhajrao\n",
      "mamthahiran\n",
      "ivonete.net.9085\n",
      "ushazworld\n",
      "hrit.ik4542\n",
      "mayakshinayak\n",
      "manojpawareailcom9820815108\n",
      "chef_shivam_pandey\n",
      "jayeetamukhopadhyay\n",
      "fath6688\n",
      "adarsh.thomas\n",
      "percjude\n",
      "mamvasu\n",
      "giselle_dcosta\n",
      "i.rishu_05\n",
      "mkkool_\n",
      "shiphnur\n",
      "rottweilerion_\n",
      "xashwaryax\n",
      "modiefoodie\n",
      "nymsisland\n",
      "vegfoodattorny\n",
      "onmsplate\n",
      "sreyabose\n",
      "fixofriend\n",
      "rupinderkour01\n",
      "afoodieteam\n",
      "shail.shailee\n",
      "_craving_hut_\n",
      "smridhigulati1\n",
      "casino.101\n",
      "swagatamsen\n",
      "arahat_\n",
      "foodshubofficial\n",
      "mr.vighnes\n",
      "dionne_gouveia\n",
      "princy_11111\n",
      "purelymarrydotcom\n",
      "nidsarda123\n",
      "i.addi_\n",
      "yut_rack\n",
      "foodineyes\n",
      "_shetrublemaker_\n",
      "yummmmy_tummmy\n",
      "preshitanarkar\n",
      "divya.dahiya\n",
      "aakashdb\n",
      "aditikapoor147\n",
      "mealhomecooked\n",
      "ankit_raj477\n",
      "anjaliepaul\n",
      "lavnderblue\n",
      "31niks\n",
      "allways_hungryy\n",
      "arpitabaruahh\n",
      "ravneet_kaurb\n",
      "imkaustubh10\n",
      "ritukaur05\n",
      "finearty\n",
      "faizanqureshi5850\n",
      "chefnavin.nishant\n",
      "quarantined93\n",
      "ihpohs\n",
      "_bint_fazal\n",
      "mrchefrahul\n",
      "harshmeet_kochhar\n",
      "hasan.mahbub.shihab\n",
      "sweet_sisters\n",
      "vaishali_jangid_1\n",
      "adv.suryavanshi\n",
      "namratha_pai_p\n",
      "followthefoodietrend\n",
      "koenachopra\n",
      "farzeennauman\n",
      "_khaadya_padarth\n",
      "anirudh27_\n",
      "meetparikh_7\n",
      "spacebot_ent\n",
      "sagana_karunakaran\n",
      "kayandesauradh\n",
      "afsarpeachy\n",
      "malathisampath\n",
      "maybe_a_unicorn_\n",
      "arpitaa.k\n",
      "dindigulponram\n",
      "nikitaparyani\n",
      "supriyasingh.s\n",
      "artisancakebites\n",
      "shanty.cooking\n",
      "peaceofcakebykmahimaa\n",
      "jnmalik1234\n",
      "crumbsindelhi\n",
      "lockdowned_foodie_chef\n",
      "thefoodies_souls\n",
      "doodle_done99\n",
      "myculinaryvibes\n",
      "nirupamarajendran\n",
      "rohan_patil50\n",
      "ju.lio8014\n",
      "swatz2311\n",
      "vickywanderer08\n",
      "rooplirai\n",
      "aceofood\n",
      "kanchanbatra_\n",
      "vinoth_______srinivasan\n",
      "mommytimesblog\n",
      "ministry_of_boulangerie\n",
      "priya_narang_bhutani\n",
      "shwetajeswani\n",
      "neha.pandey.9026\n",
      "rakshiththayi\n",
      "sgr_group_\n",
      "shashankb_01\n",
      "feedie_foodie\n",
      "brijalidobariya\n",
      "cikgu_thanasekar\n",
      "trifusion_food\n",
      "mrbadboy.420\n",
      "the_foodiebanzara\n",
      "homesmagic34\n",
      "maibhifoodie_\n",
      "kartikaryan296\n",
      "kanjibhaimaruniya\n",
      "official_vikash_gulpadiya_1\n",
      "shivamk359412020\n",
      "guna_yazhini\n",
      "aakriti_singhania\n",
      "thecakesmithbycharumehra\n",
      "mg__lucky\n",
      "giani_icecream_bathinda\n",
      "valemirandaah\n",
      "brajeshwarpoddar\n",
      "mansi_teaparty\n",
      "smritis_refection\n",
      "nihayatisavage\n",
      "cane_photograph\n",
      "blackshadow0010\n",
      "thayellemaria\n",
      "cyberpunk78\n",
      "_nehir_acar_33_\n",
      "vaibhav1ooo\n",
      "ssmriti575\n",
      "namishachadha\n",
      "__king__of__attitude\n",
      "naima.m.87\n",
      "abhishek______rko\n",
      "ruiz.yecenia\n",
      "banarasi_food_products\n",
      "insanelyarsh\n",
      "niharikamishra\n",
      "tasty_emraan_ali\n",
      "dimpytales\n",
      "muser2710\n",
      "adnanshamslive\n",
      "thehungryhump\n",
      "selfiequeenjyoti\n",
      "m.deeps\n",
      "ajaymeshram11\n",
      "goproakp\n",
      "foodasperyourmood\n",
      "shaiksirajahmed\n",
      "dhanashrees1\n",
      "mayur_marne_\n",
      "bandra_foodie\n",
      "thedreamingdusza\n",
      "dhawan_t\n",
      "i.am.pg\n",
      "perhapsabaker_\n",
      "thefoodbowll\n",
      "fitshubhu\n",
      "rahulraghav9888\n",
      "mehakdecorators\n",
      "maneet1806\n",
      "nency.patel\n",
      "indoridawat\n",
      "shilpachangder94\n",
      "growmore_interiors\n",
      "dilwalibaatien\n",
      "foodwithfacts\n",
      "himanshu.sbsc\n",
      "pranamii\n",
      "paulatin09\n",
      "arijit2775\n",
      "_mani_nithya\n",
      "havratchokri\n",
      "raj_grover\n",
      "parasnathnapit\n",
      "meow.yeou\n",
      "indiabizfiling\n",
      "ali.irshad9298\n",
      "shalu_hasija\n",
      "geekyfeast\n",
      "anubha.purwar\n",
      "the_fork_n_spoon_love_story\n",
      "_imzafarshk_\n",
      "hlohaan\n",
      "umesh_jawalekar143\n",
      "mamascookhouse\n",
      "smokeandsaltstories\n",
      "rupzz_rj\n",
      "ovenly__thehomelybakers\n",
      "mdirfanpatel242020\n",
      "pet_nation0\n",
      "explore.beautyof.india\n",
      "words_swaad_anusaar\n",
      "ranil_jsr\n",
      "sukhada_foodiecrazy\n",
      "indian_superfood\n",
      "i_am_ritesh_singh_\n",
      "m_u_muzahid\n",
      "shashankgaur1990\n",
      "foodie_addict_98\n",
      "farmnext\n",
      "adyaagarwal15\n",
      "simplecookingstories\n",
      "varsha_daksh8588\n",
      "soru.is.life\n",
      "foodi.erush\n",
      "stella.b_burini\n",
      "nitinshah5487\n",
      "cookingandbeauty89\n",
      "yash.mahap\n",
      "pawannraj\n",
      "_eatfinity_28\n",
      "shades._.of_india\n",
      "foodgaaaaaasm\n",
      "foodie19956\n",
      "thecynic_33\n",
      "_suf_iya_\n",
      "jigu_shah20\n",
      "kitchenstyleandothers\n",
      "raghav.dhaka.9\n",
      "meh_zabien\n",
      "melvinmathew12\n",
      "tasta_licious\n",
      "elevenmarketing.in\n",
      "lakshyakothari\n",
      "ravi9632sharma\n",
      "the_archi_chef\n",
      "utkarshbansal28\n",
      "eyeofbundi\n",
      "rekha_alekhya\n",
      "shivaniagarwal50\n",
      "oldpotdiaries\n",
      "crazyfor_crust\n",
      "sompura.rutvi\n",
      "deep_sojitra_29\n",
      "amrita_roxx\n",
      "surabhi.goel\n",
      "foodholicfoodie\n",
      "dr.tabassum_05\n",
      "krit.pana\n",
      "mirakkk2020\n",
      "albe_rose\n",
      "thefoodglaze\n",
      "thesaltytooth\n",
      "food_hacker00\n",
      "tassuuuu_\n",
      "liapap50\n",
      "tbb.ii\n",
      "dianarina12\n",
      "artimathur01\n",
      "_richa_saraf\n",
      "saumyasood13\n",
      "thukralsoap\n",
      "thespoonofodisha\n",
      "nenophari\n",
      "foodhut24\n",
      "caketime_ahvaz\n",
      "shreen.24\n",
      "zebahetavkar\n",
      "nandithasujir\n",
      "tiktok.india_fame\n",
      "aartikadyan\n",
      "anuragnarang\n",
      "nehapriya6519\n",
      "kapil_cooks\n",
      "ankitp33\n",
      "shailisharma910\n",
      "tejshrideepak\n",
      "tahereh_dawarzani\n",
      "ramina8497\n",
      "nebil.nizar\n",
      "vinamrekasanaa\n",
      "cook_with._me\n",
      "fblptri_\n",
      "bangalorefoodieee\n",
      "kreativekitchenbykamna\n",
      "mr_jatinjk\n",
      "foodisbae131\n",
      "sreevigneshgr\n",
      "gabrielatipian\n",
      "nupursin\n",
      "nishtha93\n",
      "kanikshekhawat\n",
      "sarvagunsomepun\n",
      "sheen.baker\n",
      "shilpakajal28\n",
      "swathi_achar_\n",
      "milimendez_2214\n",
      "hpatel0509\n",
      "chauhansamarjeet\n",
      "sb2918\n",
      "shivanid2\n",
      "nehakd\n",
      "seshabhattaraarudrra\n",
      "ahmadnajam282001\n",
      "dianantonyjs\n",
      "shambavi_ravichandar\n",
      "suni8889\n",
      "tanya_johnson_\n",
      "chaitra__\n",
      "cityfinch\n",
      "nehafatima0818\n",
      "madancas\n",
      "lizali79\n",
      "hazy009\n",
      "frankoverseas\n",
      "monicauthappa\n",
      "princemahal2019\n",
      "sruthi2591\n",
      "rajnishpriyadrshi\n",
      "sameersaple\n",
      "\n",
      "-------------------------------------\n",
      "First 500 followers of  sodelhi : \n",
      "-------------------------------------\n",
      "daljeetk37\n",
      "___ayaaaan__\n",
      "rajku636\n",
      "ambiguish\n",
      "soyal4240\n",
      "barcelonastudenthousing\n",
      "viaa_style\n",
      "tushar_badliwal\n",
      "neharikaa__\n",
      "rao_gayatri\n",
      "orangelabelz\n",
      "simranmanral\n",
      "faisu_074582\n",
      "_sarthakchaudhary_\n",
      "priyanka.sehra01\n",
      "akaur1604\n",
      "sidharth.narula\n",
      "nove.llove\n",
      "shadabalam1970\n",
      "deveshhhh_pvt\n",
      "sid____12\n",
      "odd_little_nothings\n",
      "kanishq_basoya_dellhii0001\n",
      "vickywanderer08\n",
      "_dhruv_maheshwari\n",
      "raonisha253\n",
      "pulkit5654\n",
      "harshita_thakur61\n",
      "gumberpvt\n",
      "_manishabothra_\n",
      "amit_khanagwal\n",
      "payalchaudhary29\n",
      "the.original.vagabong\n",
      "devpatel8046\n",
      "a_n_a_n_y_a._.v_e_r_m_a\n",
      "mr.aman.khan\n",
      "amretarajagopalan\n",
      "mrigank_mina\n",
      "nandani_g_upta_\n",
      "syngrafeas_4\n",
      "sahil____garg\n",
      "professionalshootss\n",
      "aarav0085\n",
      "drabu.amir\n",
      "dustyrxses3\n",
      "tmnaydav\n",
      "bhatipiya04\n",
      "rajeevchaddah2020\n",
      "iamparulyadav\n",
      "sarcasm_personified_2020\n",
      "rahulchabra707\n",
      "thefooditudeclub\n",
      "wallflower_stelpa\n",
      "pankaj_arora_1\n",
      "gd3386871gmail.com24\n",
      "famous.facees\n",
      "lensing_it_my_way\n",
      "rahul_ranar\n",
      "rohankshetry1\n",
      "awon_ton_\n",
      "_shiwaniii_\n",
      "_priyal__sharma_\n",
      "amansachdeva__\n",
      "gurmxxt_\n",
      "shubham1rajput\n",
      "anmolgandhi23.ag\n",
      "_ayushisahu_012\n",
      "iampalashsharma\n",
      "imanoj_06\n",
      "blackwhiteforphoto\n",
      "athena.sule\n",
      "markanmudit\n",
      "meme_zilla_0\n",
      "berry_blosoom\n",
      "freegadgetz\n",
      "yatikamboj\n",
      "piya_jaiswal.08_\n",
      "sheetalchawla_98\n",
      "vedika_jais\n",
      "khandelwal2003_\n",
      "kwatra184\n",
      "_.shalini_singh._\n",
      "tales_that_travels\n",
      "activitysports\n",
      "ditika_jain\n",
      "newintown07\n",
      "slimm_shaddyyyy\n",
      "styleupwithparul\n",
      "palak_kohli17\n",
      "riya_gupta25\n",
      "umeshvats994\n",
      "beatnik.nowhere\n",
      "sharmajikichotibeti\n",
      "pleasurabletales\n",
      "gurjar___________\n",
      "surprisegenie\n",
      "m_a_i_d_i_\n",
      "nishant.soni.bookseller\n",
      "nishaaaaant\n",
      "kshitij28jain\n",
      "stranger02_\n",
      "harshit2526\n",
      "resilient_0528\n",
      "eshu_verma1323\n",
      "thelegalshow\n",
      "sparsh_vashishta33\n",
      "diksha_kathikar\n",
      "iamanishyadav\n",
      "dtomar20\n",
      "himanshujain2412\n",
      "shivanis07\n",
      "ankur.singh07\n",
      "deep_warrior\n",
      "mansi_.verma\n",
      "official_hitendra_sinh3\n",
      "aasthakapoor_25\n",
      "bhanvispam\n",
      "ravi.kumar5148\n",
      "_iamraunak_\n",
      "aashna_tomar\n",
      "1212jayesh\n",
      "dugdug_inhimachal\n",
      "rakshitpareek\n",
      "kill.er6262\n",
      "yoda8013\n",
      "gauravlly2\n",
      "priyanshijain.23\n",
      "kumarsushil01\n",
      "cheshta_19\n",
      "sankalp4040\n",
      "_vegforlife\n",
      "nawab_ziya_khan\n",
      "instagrubveller\n",
      "yana_jerath\n",
      "akashkachara\n",
      "maahi1716\n",
      "_unknown_14___\n",
      "loveheart0047\n",
      "iamarunprajapati\n",
      "sikander_mansure0001\n",
      "mdsadikmalik\n",
      "gaur9288\n",
      "surai46fashioninn\n",
      "its_pradyumna\n",
      "keshuchauhanpvt_pardhanji_5678\n",
      "talented_mrt\n",
      "thekindestrude\n",
      "thapaakanksha\n",
      "storyby_richa\n",
      "sonalisingla1993\n",
      "annavt02\n",
      "ig_prashant\n",
      "shubhanshu_ssr_\n",
      "priyaa4433\n",
      "imritesh.rishi\n",
      "singha_veere7\n",
      "tmahajan.25\n",
      "dank.quote\n",
      "triptisharma.official\n",
      "delhi.photographs.official\n",
      "its.bathamrk\n",
      "apurvasindhu\n",
      "thakurbhanu.singh.319\n",
      "jkspampvtt\n",
      "potatoooxchips\n",
      "sarfarazsarfaraz56\n",
      "namzz_world\n",
      "taruni_budhiraja\n",
      "shama_saifee\n",
      "sahilkamali38\n",
      "amulyaaaaaa\n",
      "oxytocinal\n",
      "fenatemami\n",
      "asaad772\n",
      "sakshi___chopra\n",
      "harshita_xvi\n",
      "ashray.puri\n",
      "embrace_the_imperfection\n",
      "rk2789__\n",
      "_ishikaaaaaaaa\n",
      "shikha_sharmaa\n",
      "megh.kaur\n",
      "foodgazing_trio\n",
      "coolsmashy\n",
      "yash.vashisht\n",
      "u_never_know2\n",
      "shippra_govil\n",
      "drguneet3\n",
      "voiceofsprysoul\n",
      "vatsal_sri18\n",
      "akanshaa_mathur\n",
      "sundriyal1103\n",
      "manish4life__\n",
      "ipgasf_delhi\n",
      "__ridhimaa__\n",
      "surabhibaksi\n",
      "kritiwoohoo\n",
      "shellfish_pg\n",
      "mirch_masalarestaurant\n",
      "lofty_ideaz\n",
      "_kardong\n",
      "vivid_snaps555\n",
      "__mr_un_known_\n",
      "flicknfeet\n",
      "neha_manral7\n",
      "rashh_bhasin\n",
      "aditi_juneja\n",
      "sachinalavandi\n",
      "insightful_psycho\n",
      "fuuu_fuuu_\n",
      "caloriesnotcounted\n",
      "shikhar_25\n",
      "memelover449\n",
      "isha_creationz_\n",
      "sunilrathod8653\n",
      "palak_shah_visuals_2387\n",
      "whyybeeee\n",
      "khwabeeda4\n",
      "globaldelta8400\n",
      "crazy_foodlove\n",
      "prosto.vkysno1\n",
      "kamlesh3320kumar\n",
      "three_foodie_sisters\n",
      "fashionchub\n",
      "americanbagelfactory\n",
      "i_bharat07\n",
      "gogallery9\n",
      "mr_krishna__2829\n",
      "bingeadventurer\n",
      "kobil_0707\n",
      "vaaniii97\n",
      "ankyvee\n",
      "be_a_donor\n",
      "sabhya_sgh27\n",
      "suneeta498\n",
      "pahadi_foodies_swag\n",
      "u_nvr_knw\n",
      "quote_blooded\n",
      "sm_pvt26\n",
      "vaditiverma\n",
      "opositegenders\n",
      "rishikush152\n",
      "annukumari810\n",
      "foodie_auditor\n",
      "mansiibansal\n",
      "onmsplate\n",
      "foodmapagra\n",
      "jignashamistryy\n",
      "khanabdullah.786\n",
      "arcadianslife\n",
      "ishukwatra\n",
      "abdullahnazeernadwi\n",
      "dullanarur\n",
      "abhisingh.884\n",
      "sandrocottus93\n",
      "rohit_rajput1104\n",
      "hitss_j\n",
      "preetynarang94\n",
      "noorshaikh90909\n",
      "iamreha13\n",
      "foodieartist_\n",
      "dishaahuja13\n",
      "thesortedgirl\n",
      "arnav_madaan\n",
      "_meramann\n",
      "dheeraj8sep\n",
      "himanshujoharphotography\n",
      "yash____juneja\n",
      "kothari1442\n",
      "asantoshi\n",
      "tigerarya2222\n",
      "doccookie\n",
      "ashita_arora38\n",
      "rk2033\n",
      "manishsaxena305\n",
      "brozkhana\n",
      "madaan__2002\n",
      "spanishonelook\n",
      "sulandar.singh.16\n",
      "naman_2020_\n",
      "290986_j\n",
      "raghv.goel\n",
      "sauravjha693\n",
      "fresh_on_the_plate_\n",
      "_sheena.bhatia_\n",
      "manisha_yadav_rao_\n",
      "aquarian_nayab\n",
      "talklessboy1\n",
      "_kashika_22\n",
      "pranjals905\n",
      "riyaverma.riyaverma.16100\n",
      "themaahiway\n",
      "thaat_dope_philo\n",
      "sunil.rana_\n",
      "baweja_jaspreet\n",
      "koshika_chaudhary\n",
      "aroraaman045\n",
      "humdingerskysasta\n",
      "abrolv\n",
      "monty7861794\n",
      "yashpanday\n",
      "yash_mishra2575\n",
      "hunnie_h.arora\n",
      "ashiji_ka_khana\n",
      "rachel_zane66\n",
      "apoorvaa.12\n",
      "humour_gram._\n",
      "mm_meditationminute\n",
      "_the__plate_\n",
      "sk_1565\n",
      "nikiita_ojasspirit\n",
      "nikita.sharma.22\n",
      "_mr_attu_shaikh_\n",
      "stonedgyani\n",
      "snehagulati14\n",
      "mallika_bhaskar\n",
      "destinyydesigner\n",
      "oberaineena\n",
      "rajkumarjangra\n",
      "vandana7385\n",
      "thescribblersdais\n",
      "traveljunkie866\n",
      "arpit_khandelwal5\n",
      "k._bhavika\n",
      "tanvi0212\n",
      "aashima0089\n",
      "chinu_peter\n",
      "uh_zee_tee\n",
      "rahuloxo\n",
      "viskarmarinku\n",
      "untoldfeelings93\n",
      "looney_toons\n",
      "kanikanegi_2908\n",
      "ravi.rana04\n",
      "aashish_av\n",
      "pad_emic.india\n",
      "weave_the_leaves\n",
      "arsheeeeya\n",
      "_.palakkkkkkk\n",
      "i.m.anandita\n",
      "haldarnobab\n",
      "jasnooooor\n",
      "bhooka_devta\n",
      "ritu.panwar_13\n",
      "foodislife6209\n",
      "foodtrav9\n",
      "fashionovaindia\n",
      "sharmendraagarwal\n",
      "anniket.123\n",
      "ishaandixit22\n",
      "falguni_surana\n",
      "pavanpalguna\n",
      "shabzsharibkhan\n",
      "yush_nirwal_\n",
      "devika_2611\n",
      "haluk_levent.35\n",
      "mohitjaat249\n",
      "mahesh_jethalia\n",
      "payodhim18\n",
      "kashina_chadha\n",
      "infinity_carvings\n",
      "startnachieve\n",
      "thesky.traveller\n",
      "grumpyykid\n",
      "iqra.hafiza\n",
      "relatewithmylife\n",
      "artiste.sidd.01\n",
      "girikabagga\n",
      "rashi_sachdeva_kaushal\n",
      "khushi_gund\n",
      "_amit_0031\n",
      "lens_serenity\n",
      "sukh_2001\n",
      "mohiit.jain\n",
      "candyandtiger\n",
      "shivam_daksh07\n",
      "findyourpassion2\n",
      "boxyourstock\n",
      "nashtemeinkyahai\n",
      "2711.noor\n",
      "ramsuri2000\n",
      "nittumanishgupta\n",
      "sanyadua11\n",
      "anni_0721\n",
      "nivedita._\n",
      "annanyamittal\n",
      "betiyan_foundation\n",
      "girlwholovescricket\n",
      "mr_kr_official\n",
      "rajatbhallaofficial\n",
      "bhawana.tiwari\n",
      "_shetrublemaker_\n",
      "mohitverma7306\n",
      "blade_runner_42\n",
      "just_regular2020\n",
      "preshitanarkar\n",
      "bhavleenpvt___\n",
      "nainysingh08\n",
      "_ritimalik_\n",
      "aditikapoor147\n",
      "pvt.13.manyaaaaaa\n",
      "nitin.arora.9210\n",
      "jessicadarvy\n",
      "gauravdrycleners9311490707\n",
      "shilpathapa94\n",
      "peenaoberoi\n",
      "_dramebaaz__\n",
      "amitkush37\n",
      "_aditya_5802\n",
      "foody_teller\n",
      "gupta.ritika1619\n",
      "_manzzzzz\n",
      "chattybansal\n",
      "chattyapaa\n",
      "nayantosh\n",
      "adelicious777\n",
      "abdulkhalikabdulkhalik439\n",
      "ankitta3142\n",
      "iamradz93\n",
      "majilaniahmad1\n",
      "sangwan_2404\n",
      "rathi.shrinivas\n",
      "khantibhubaneswaria\n",
      "savita.kitchen\n",
      "pixelcaption18\n",
      "sayani_sarkar\n",
      "sandy_shardul_3\n",
      "muskaanthapa4\n",
      "asha_adhikari_55\n",
      "mxnxvjindxl\n",
      "royale.eventmanagement\n",
      "ashupargaien\n",
      "_navya29_\n",
      "pr.iyanshi529\n",
      "jatinwahii\n",
      "lifefiller_services\n",
      "carlo_ilgrande\n",
      "malasi.aakshi\n",
      "shraddhakhandelwal_makeup\n",
      "anilk_umar60342\n",
      "zaikadillikaa\n",
      "rishav_61\n",
      "sheen_shopping_spot\n",
      "js83may2017\n",
      "meg_was\n",
      "passagethroughthelabyrinth\n",
      "priyankahnarbadi\n",
      "simargulatii\n",
      "madover_cooking\n",
      "sneh.apei\n",
      "amxindia\n",
      "vishu270\n",
      "shivamyadav_0\n",
      "anikaasinghx\n",
      "ankitchoudhary80\n",
      "sparkling5_soul\n",
      "crumbsindelhi\n",
      "zaidi_mehwish07\n",
      "anisha240890\n",
      "anku991\n",
      "srishti.parmar.33\n",
      "eazygo2608\n",
      "sona2_398\n",
      "ju.lio8014\n",
      "smart_ghollu_001\n",
      "madasu.raviteja\n",
      "itscharuarora\n",
      "ansh_jain08\n",
      "food_petal29\n",
      "shiwangi.singh_\n",
      "iamxhubhamm\n",
      "soumyag07\n",
      "sagarpaswan158\n",
      "omgupta4413\n",
      "rpoii.12\n",
      "sanskrity_jain\n",
      "hearthackertarun\n",
      "head._over_meals\n",
      "foodofyours\n",
      "joker00149\n",
      "surbhi.arya.56\n",
      "risha_bhjain5881\n",
      "b.gauriii\n",
      "thedailymemoirr\n",
      "dantale\n",
      "stylishsketcher\n",
      "yoursuade\n",
      "woofyygraphy\n",
      "sham_run\n",
      "rimutree\n",
      "harmeekmatharoo\n",
      "anjila_kindra\n",
      "rameez_j_siddiqui\n",
      "adhm.dear\n",
      "pawan.sha92\n",
      "rabhnit_kaur_virdi\n",
      "scorpion_0016\n",
      "yunusyunusansari\n",
      "__sugu__verma__\n",
      "_rajat.soni_\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    p = profiles[i]\n",
    "    print(\"-------------------------------------\")\n",
    "    print(\"First 500 followers of \",p,\": \\n-------------------------------------\")\n",
    "    for j in range(500):\n",
    "        print(followers[i][j]) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "following = []                      # followers of foodtalkindia whom I follow\n",
    "s_box= wait.until(EC.presence_of_element_located((By.XPATH,\"//input[@placeholder = 'Search']\"))) \n",
    "s_box.send_keys('foodtalkindia')\n",
    "x = wait.until(EC.presence_of_element_located((By.CLASS_NAME,'yCE8d ')))     #selecting the first option\n",
    "x.click()\n",
    "y = wait.until(EC.presence_of_element_located((By.XPATH,\"//a[@href = '/foodtalkindia/followers/']\"))) #followers of foodtalkindia\n",
    "y.click()\n",
    "\n",
    "div = wait.until(EC.presence_of_element_located((By.CLASS_NAME,'PZuss')))  #waiting for the followers list\n",
    "fols = wait.until(EC.presence_of_element_located((By.CLASS_NAME,'isgrP')))\n",
    "counter_ = len(div.find_elements_by_tag_name(\"li\"))\n",
    "\n",
    "if(counter_<500):                 # scrolling till 500 followers\n",
    "    while counter_ < 500:\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", fols)\n",
    "        new_count = len(div.find_elements_by_tag_name(\"li\"))\n",
    "        time.sleep(1)\n",
    "        counter_ = new_count\n",
    "\n",
    "div = driver.find_element_by_class_name('PZuss')\n",
    "followers_list = div.find_elements_by_xpath(\"./li\")\n",
    "\n",
    "for pf in followers_list:\n",
    "    f = pf.find_element_by_xpath('div/div[2]/button') \n",
    "    if f.text=='Following':\n",
    "        name = pf.find_element_by_xpath('div/div[1]/div[2]/div[1]/a').text #from the list fetching the names of followers\n",
    "        following.append(name)  \n",
    "\n",
    "close = driver.find_element_by_xpath(\"//*[@aria-label='Close']\")\n",
    "close.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_followers = []  #list of my profile followers\n",
    "followers_=[]\n",
    "my_profile  = driver.find_element_by_xpath(\"//div[contains(@class, 'SKguc')]/a\")  #opening my profile\n",
    "my_profile.click()\n",
    "time.sleep(3)\n",
    "\n",
    "followers = driver.find_element_by_xpath(\"//a[contains(@class,'-nal3 ')]\")    #checking my followers\n",
    "total = followers.text.split()[0]\n",
    "total = int(total)\n",
    "followers.click()\n",
    "div =  wait.until(EC.presence_of_element_located((By.CLASS_NAME,'PZuss')))\n",
    "fols = wait.until(EC.presence_of_element_located((By.CLASS_NAME,'isgrP')))\n",
    "counter_ = len(div.find_elements_by_tag_name('li'))\n",
    "\n",
    "while counter_ < total:                       # scrolling till 500 followers\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", fols)\n",
    "        new_count = len(div.find_elements_by_tag_name(\"li\"))\n",
    "        time.sleep(1)\n",
    "        counter_ = new_count\n",
    "\n",
    "my_followers_ = div.find_elements_by_tag_name('li')\n",
    "#usernamepath = '/div/div[2]/div[1]/div/div/a'\n",
    "\n",
    "for f in my_followers_:                             \n",
    "    username = f.text.split()[0]      #to split the names from the links\n",
    "    my_followers.append(username)\n",
    "    if username in following:\n",
    "        followers_.append(username)  #storing the followers of the handle seperately in a list\n",
    "\n",
    "ans = []\n",
    "for f in following:\n",
    "    if f not in followers_:\n",
    "        ans.append(f)\n",
    "close = driver.find_element_by_xpath(\"//*[@aria-label='Close']\")       # to close the list of followers \n",
    "close.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Followers of foodtalkindia whom I follow but don't follow me: \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#to display the output\n",
    "print(\"Followers of foodtalkindia whom I follow but don't follow me: \")\n",
    "if len(ans)==0:\n",
    "    print(\"None\")\n",
    "else:\n",
    "    print()\n",
    "    for i in ans:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Check the story of ‘coding.ninjas’\n",
    "Consider the following Scenarios and print error messages accordingly -\n",
    "\n",
    "> - If You have already seen the story\n",
    "> - Or The user has no story.\n",
    "> - Or View the story if not yet seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visiting coding ninja\n",
    "s_box = driver.find_element_by_xpath(\"//input[@placeholder = 'Search']\") \n",
    "s_box.send_keys('coding.ninjas')\n",
    "handle = wait.until(EC.presence_of_element_located((By.XPATH,\"//div[@class = 'fuqBx']/a\")))\n",
    "handle.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story has been viewed\n"
     ]
    }
   ],
   "source": [
    "story = wait.until(EC.presence_of_element_located((By.CLASS_NAME,'_2dbep ')))  #to chech the story status, first locating the story icon\n",
    "canvas = driver.find_element_by_xpath(\"//*[starts-with(@class,'RR-M- ')]\")    #the story display canvas is located\n",
    "if canvas.get_attribute('class')=='RR-M- ':    #when canvas and div tag attributes matches then no story posted\n",
    "    print(\"User has no Story\")\n",
    "else:\n",
    "    if int(driver.find_element_by_class_name('CfWVH').get_attribute('width'))==191: #here mathching with either height or width of the canvas\n",
    "        print(\"Story has been viewed\")                                      # to decide whether story viewed or not\n",
    "    else:\n",
    "        print(\"Story not viewed \")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
